{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if we still need this\n",
    "\n",
    "def build_worker_agent():\n",
    "    \"\"\"Builds the LangGraph that functions as the ReAct Worker Agent.\"\"\"\n",
    "    \n",
    "    # 1. The toolkit for the agent\n",
    "    tools = [get_knowledge_base_chunks, geolocate_ip, get_places]\n",
    "    \n",
    "    # 2. The agent's \"brain\" (LLM)\n",
    "    # Note: \"gpt-4o-mini\" is the current standard name for this model class.\n",
    "    # Using the name from your file for consistency.\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    # Bind the tools to the LLM, making it \"tool-aware\"\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # 3. The agent's \"instructions\" (Prompt)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "       (\"system\", \"\"\"\n",
    "        You are a specialized research agent. Your job is to receive a task and use your tools to find the required information.\n",
    "        After using your tools, you must compile all the results into a single, structured JSON object.\n",
    "        Do not respond in conversational language; your output must be only the final JSON report.\n",
    "        \"\"\"),\n",
    "       (\"human\", \"{input}\"), \n",
    "       (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "    \n",
    "    # The runnable chain for the agent's brain\n",
    "    chain = prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb252c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "class WorkerAgentState(TypedDict): \n",
    "    from typing import TypedDict\n",
    "    messages: list[str] # We need this messages key for our react agent to use\n",
    "    workeragentsummary: str\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84231b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_agent_prompt = \"\"\"\n",
    "    You are a helpful assistant who is a research agent. You have access to the static knowledge base that has information regarding the regulations and laws of recycling and waste disposal in three cities: NYC, LA, and Chicago. You also have access to the google_search tool the get_knowledge_basez_chunks tool. You will provide StructuredOutput from the knowledge base that you have been provided and relay it to the Supervisor Agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(model_provider=\"openai\", model=\"gpt-4.1-mini\")\n",
    "\n",
    "#define the tools as lists\n",
    "worker_agent_tools = [get_knowledge_base_chunks, geolocate_ip, get_places, google_search]\n",
    "worker_agent = create_react_agent(model=llm, tools=worker_agent_tools, prompt=worker_agent_prompt)\n",
    "\n",
    "def worker_agent_node(state: WorkerAgentState, config: Optional[RunnableConfig]): \n",
    "    response = worker_agent.invoke({\"messages\": state[\"messages\"][-1]}) #Passes in the latest message from state\n",
    "    result = response[\"messages\"][-1] \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [result], \n",
    "        \"worker_agent_output\": result\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
